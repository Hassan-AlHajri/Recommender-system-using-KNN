{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy import spatial\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "anime = pd.read_csv(\"my-data/anime.csv\", error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We have missing data, so we need to clean.\n",
    "# from analyzing the data, if the type is a movie and the number of episodes is unkown, then we can put 1.  \n",
    "# For OVA(Original Video Animation), these are generally one/two episode long animes. I’ve decided to fill the unknown numbers of episodes with 1 again.\n",
    "\n",
    "# For all the other animes with unknown number of episodes, I’ve filled the known values with the median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "anime.loc[(anime[\"type\"]==\"OVA\") & (anime[\"episodes\"]==\"Unknown\"),\"episodes\"] = \"1\"\n",
    "\n",
    "anime.loc[(anime[\"type\"] == \"Movie\") & (anime[\"episodes\"] == \"Unknown\")] = \"1\"\n",
    "  \n",
    "anime[\"episodes\"] = anime[\"episodes\"].map(lambda x:np.nan if x==\"Unknown\" else x)\n",
    "\n",
    "anime[\"episodes\"].fillna(anime[\"episodes\"].median(),inplace = True)\n",
    "\n",
    "\n",
    "anime[\"rating\"] = anime[\"rating\"].astype(float)\n",
    "anime[\"rating\"].fillna(anime[\"rating\"].median(),inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "anime_features = pd.concat([anime[\"genre\"].str.get_dummies(sep=\",\"),\n",
    "                            pd.get_dummies(anime[[\"type\"]]),\n",
    "                            anime[[\"rating\"]],anime[\"episodes\"]],axis=1)\n",
    "# you can see the features by using anime_features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.  ,  0.  ,  0.  , ...,  0.  ,  0.93,  0.  ],\n",
       "       [ 1.  ,  0.  ,  0.  , ...,  1.  ,  0.92,  0.03],\n",
       "       [ 0.  ,  0.  ,  1.  , ...,  1.  ,  0.92,  0.03],\n",
       "       ..., \n",
       "       [ 0.  ,  0.  ,  0.  , ...,  0.  ,  0.43,  0.  ],\n",
       "       [ 0.  ,  0.  ,  0.  , ...,  0.  ,  0.44,  0.  ],\n",
       "       [ 0.  ,  0.  ,  0.  , ...,  0.  ,  0.5 ,  0.  ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#I used MinMaxScaler from scikit-learn as it scales the values from 0–1.\n",
    "min_max_scaler = MinMaxScaler()\n",
    "anime_features = min_max_scaler.fit_transform(anime_features)\n",
    "np.round(anime_features,2)\n",
    "# number 2 in round means two decimal points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The scaling function (MinMaxScaler) returns a numpy array containing the features. Then we fit the KNN model from scikit learn to the data and calculate the nearest neighbors for each distances. In this case I’ve used the unsupervised NearestNeighbors method for implementing neighbor searches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nbrs = NearestNeighbors(n_neighbors=20, algorithm='ball_tree').fit(anime_features)\n",
    "\n",
    "distances, indices = nbrs.kneighbors(anime_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  Returns the index of the anime if (given the full name)\n",
    "def get_index_from_name(name):\n",
    "    return anime[anime[\"name\"]==name].index.tolist()[0]\n",
    "    \n",
    "all_anime_names = list(anime.name.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of KNN Recommendation\n",
      "Naruto: Shippuuden\n",
      "Katekyo Hitman Reborn!\n",
      "Dragon Ball Z\n",
      "Dragon Ball Kai\n",
      "Bleach\n",
      "Dragon Ball Kai (2014)\n",
      "Shijou Saikyou no Deshi Kenichi\n",
      "Rekka no Honoo\n",
      "Sakigake!! Otokojuku\n",
      "Medaka Box Abnormal\n",
      "Kenyuu Densetsu Yaiba\n",
      "Ben-To\n",
      "Boruto: Naruto the Movie - Naruto ga Hokage ni Natta Hi\n",
      "Kurokami The Animation\n",
      "Boruto: Naruto the Movie\n",
      "Naruto x UT\n",
      "Naruto: Shippuuden Movie 4 - The Lost Tower\n",
      "Naruto: Shippuuden Movie 3 - Hi no Ishi wo Tsugu Mono\n",
      "Virtua Fighter\n"
     ]
    }
   ],
   "source": [
    "# Prints the top K similar animes after querying\n",
    "def print_similar_animes(query=None):\n",
    "\n",
    "    if query:\n",
    "        found_id = get_index_from_name(query)\n",
    "        for id in indices[found_id][1:]:\n",
    "            print(anime.ix[id][\"name\"])\n",
    "            \n",
    "print(\"Start of KNN Recommendation\")\n",
    "pred=print_similar_animes(query=\"Naruto\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loading another dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating\n",
       "0      196      242       3\n",
       "1      186      302       3\n",
       "2       22      377       1\n",
       "3      244       51       2\n",
       "4      166      346       1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_cols = ['user_id', 'item_id', 'rating']\n",
    "ratings = pd.read_csv('my-data/u.data', sep='\\t', names=r_cols, usecols=range(3))\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now, we'll group everything by movie ID(item_id), and compute the total number of ratings (each movie's popularity) and the average rating for every movie.\n",
    "# The raw number of ratings isn't very useful for computing distances between movies, so we'll create a new DataFrame that contains the normalized number of ratings. So, a value of 0 means nobody rated it, and a value of 1 will mean it's the most popular movie there is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        rating          \n",
      "          size      mean\n",
      "item_id                 \n",
      "1          452  3.878319\n",
      "2          131  3.206107\n",
      "3           90  3.033333\n",
      "4          209  3.550239\n",
      "5           86  3.302326\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.774914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.223368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.152921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.357388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.146048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             size\n",
       "item_id          \n",
       "1        0.774914\n",
       "2        0.223368\n",
       "3        0.152921\n",
       "4        0.357388\n",
       "5        0.146048"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movieProperties = ratings.groupby('item_id').agg({'rating': [np.size, np.mean]})\n",
    "print(movieProperties.head())\n",
    "\n",
    "movieNumRatings = pd.DataFrame(movieProperties['rating']['size'])\n",
    "movieNormalizedNumRatings = movieNumRatings.apply(lambda x: (x - np.min(x)) / (np.max(x) - np.min(x)))\n",
    "movieNormalizedNumRatings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now, let's get the genre information from the u.item file. The way this works is there are 19 fields, each corresponding to a specific genre - a value of '0' means it is not in that genre, and '1' means it is in that genre. A movie may have more than one genre associated with it.\n",
    "\n",
    "# Then, we'll put together everything into one big Python dictionary called movieDict. Each entry will contain the movie name, list of genre values, the normalized popularity score, and the average rating for each movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Toy Story (1995)',\n",
       " [0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " 0.77491408934707906,\n",
       " 3.8783185840707963)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movieDict = {}\n",
    "with open('my-data/u.item') as f:\n",
    "    temp = ''\n",
    "    for line in f:\n",
    "        fields = line.rstrip('\\n').split('|')\n",
    "        movieID = int(fields[0])\n",
    "        name = fields[1]\n",
    "        genres = fields[5:25]\n",
    "        genres = map(int, genres)\n",
    "        movieDict[movieID] = (name, genres, movieNormalizedNumRatings.loc[movieID].get('size'), movieProperties.loc[movieID].rating.get('mean'))\n",
    "# For example, here's the record we end up with for movie ID 1, (Toy Story)\n",
    "movieDict[1] \n",
    "# you can change the number of movieDict[num]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now, let's create a function that computes the (distance) between two movies based on how similar their genres are, and how similar their popularity is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.08419243986\n",
      "('Toy Story (1995)', [0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 0.77491408934707906, 3.8783185840707963)\n",
      "('Get Shorty (1995)', [0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 0.35738831615120276, 3.5502392344497609)\n"
     ]
    }
   ],
   "source": [
    "def ComputeDistance(a, b):\n",
    "    genresA = a[1]\n",
    "    genresB = b[1]\n",
    "    genreDistance = spatial.distance.cosine(genresA, genresB)\n",
    "    popularityA = a[2]\n",
    "    popularityB = b[2]\n",
    "    popularityDistance = abs(popularityA - popularityB)\n",
    "    return genreDistance + popularityDistance\n",
    "# For example,here we compute the distance between two movies (movie id 2 and movie id 4)\n",
    "print(ComputeDistance(movieDict[1], movieDict[4]))\n",
    "# you can compute any other movies by changing the movieDict[number]\n",
    "print movieDict[1]\n",
    "print movieDict[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now, let's compute the distance between some given test movie (Toy Story, in this example) and all of the movies in our data set. then sort those by distance, and print out the K nearest neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liar Liar (1997)\n",
      "Aladdin (1992)\n",
      "Willy Wonka and the Chocolate Factory (1971)\n",
      "Monty Python and the Holy Grail (1974)\n",
      "Full Monty, The (1997)\n",
      "George of the Jungle (1997)\n",
      "Beavis and Butt-head Do America (1996)\n",
      "Birdcage, The (1996)\n",
      "Home Alone (1990)\n",
      "Aladdin and the King of Thieves (1996)\n"
     ]
    }
   ],
   "source": [
    "def getNeighbors(movieID, K):\n",
    "    distances = []\n",
    "    for movie in movieDict:\n",
    "        if (movie != movieID):\n",
    "            dist = ComputeDistance(movieDict[movieID], movieDict[movie])\n",
    "            distances.append((movie, dist))\n",
    "    distances.sort(key=operator.itemgetter(1))\n",
    "    neighbors = []\n",
    "    for x in range(K):\n",
    "        neighbors.append(distances[x][0])\n",
    "    return neighbors\n",
    "\n",
    "K = 10\n",
    "avgRating=0\n",
    "neighbors = getNeighbors(1, K)\n",
    "for neighbor in neighbors:\n",
    "    print (movieDict[neighbor][0])\n",
    "    # we can print the average rating also by using the print bellow\n",
    "    #print movieDict[neighbor][0] + \" \" + str(movieDict[neighbor][3])\n",
    "avgRating /= float(K)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
